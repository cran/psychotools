
R version 3.0.2 (2013-09-25) -- "Frisbee Sailing"
Copyright (C) 2013 The R Foundation for Statistical Computing
Platform: x86_64-unknown-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> pkgname <- "psychotools"
> source(file.path(R.home("share"), "R", "examples-header.R"))
> options(warn = 1)
> library('psychotools')
> 
> base::assign(".oldSearch", base::search(), pos = 'CheckExEnv')
> cleanEx()
> nameEx("FirstNames")
> ### * FirstNames
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: FirstNames
> ### Title: Popularity of First Names
> ### Aliases: FirstNames
> ### Keywords: datasets
> 
> ### ** Examples
> 
> data("FirstNames", package = "psychotools")
> summary(FirstNames$preference)
                      >   <
Tim      : Lucas     87 105
Tim      : Michael  103  89
Lucas    : Michael  112  80
Tim      : Robin    125  67
Lucas    : Robin    129  63
Michael  : Robin    106  86
Tim      : Benedikt 140  52
Lucas    : Benedikt 146  46
Michael  : Benedikt 129  63
Robin    : Benedikt 127  65
Tim      : Julius   109  83
Lucas    : Julius   120  72
Michael  : Julius   103  89
Robin    : Julius    95  97
Benedikt : Julius    73 119
> covariates(FirstNames$preference)
         vowel
Tim      front
Lucas     back
Michael  front
Robin     back
Benedikt front
Julius    back
> 
> 
> 
> cleanEx()
> nameEx("GermanParties2009")
> ### * GermanParties2009
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: GermanParties2009
> ### Title: Choice among German Political Parties
> ### Aliases: GermanParties2009
> ### Keywords: datasets
> 
> ### ** Examples
> 
> data("GermanParties2009", package = "psychotools")
> summary(GermanParties2009$preference)
                    >   <
none    : Linke   119  73
none    : Gruene   25 167
Linke   : Gruene   23 169
none    : SPD      38 154
Linke   : SPD      34 158
Gruene  : SPD     124  68
none    : CDU/CSU  69 123
Linke   : CDU/CSU  76 116
Gruene  : CDU/CSU 128  64
SPD     : CDU/CSU 125  67
none    : FDP      83 109
Linke   : FDP      70 122
Gruene  : FDP     137  55
SPD     : FDP     134  58
CDU/CSU : FDP     106  86
> 
> 
> 
> cleanEx()
> nameEx("MemoryDeficits")
> ### * MemoryDeficits
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: MemoryDeficits
> ### Title: Memory Deficits in Psychiatric Patients
> ### Aliases: MemoryDeficits
> ### Keywords: datasets
> 
> ### ** Examples
> 
> data("MemoryDeficits", package = "psychotools")
> aggregate(cbind(E1, E2, E3, E4) ~ trial + group, MemoryDeficits, sum)
   trial      group  E1 E2  E3  E4
1      1     Schizo  31 15 154 380
2      2     Schizo  79 45 163 293
3      3     Schizo 127 63 160 230
4      4     Schizo 148 74 149 209
5      5     Schizo 176 73 152 179
6      6     Schizo 198 67 138 177
7      1  SchizoCtl  49 31 149 271
8      2  SchizoCtl 116 66 151 167
9      3  SchizoCtl 190 66 136 108
10     4  SchizoCtl 243 68 108  81
11     5  SchizoCtl 269 77  81  73
12     6  SchizoCtl 301 76  71  52
13     1 OrganicAlc  20  9  91 300
14     2 OrganicAlc  34 18 102 266
15     3 OrganicAlc  43 30 102 245
16     4 OrganicAlc  57 25 114 224
17     5 OrganicAlc  58 35  98 229
18     6 OrganicAlc  65 29 100 226
19     1     AlcCtl  45 24  97 254
20     2     AlcCtl 106 41 107 166
21     3     AlcCtl 171 40 110  99
22     4     AlcCtl 202 50  79  89
23     5     AlcCtl 217 64  69  70
24     6     AlcCtl 243 64  65  48
> 
> 
> 
> cleanEx()
> nameEx("PCModel.fit")
> ### * PCModel.fit
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: PCModel.fit
> ### Title: Partial Credit Model Fitting Function
> ### Aliases: PCModel.fit print.PCModel summary.PCModel
> ###   print.summary.PCModel coef.PCModel logLik.PCModel vcov.PCModel
> ### Keywords: regression
> 
> ### ** Examples
> 
> 
> ## Verbal aggression data
> data("VerbalAggression", package = "psychotools")
> 
> ## Partial credit model for the other-to-blame situations
> pcm <- PCModel.fit(VerbalAggression$resp[, 1:12])
> summary(pcm)

Partial credit model

Item category parameters:
               Estimate Std. Error z value Pr(>|z|)    
S1WantCurse-C2  0.43145    0.25453   1.695 0.090062 .  
S1DoCurse-C1   -0.10659    0.21858  -0.488 0.625811    
S1DoCurse-C2    0.59544    0.35874   1.660 0.096954 .  
S1WantScold-C1  0.56366    0.21616   2.608 0.009118 ** 
S1WantScold-C2  1.25444    0.35762   3.508 0.000452 ***
S1DoScold-C1    0.58144    0.21183   2.745 0.006053 ** 
S1DoScold-C2    1.70747    0.36228   4.713 2.44e-06 ***
S1WantShout-C1  0.76676    0.20960   3.658 0.000254 ***
S1WantShout-C2  2.30309    0.36960   6.231 4.63e-10 ***
S1DoShout-C1    1.62445    0.21789   7.455 8.97e-14 ***
S1DoShout-C2    3.47896    0.38894   8.945  < 2e-16 ***
S2WantCurse-C1 -0.56274    0.22857  -2.462 0.013818 *  
S2WantCurse-C2 -0.07855    0.36200  -0.217 0.828213    
S2DoCurse-C1    0.24407    0.21621   1.129 0.258966    
S2DoCurse-C2    0.95149    0.35768   2.660 0.007809 ** 
S2WantScold-C1  0.39773    0.21547   1.846 0.064912 .  
S2WantScold-C2  1.14034    0.35789   3.186 0.001441 ** 
S2DoScold-C1    0.91216    0.21077   4.328 1.51e-05 ***
S2DoScold-C2    2.41128    0.37018   6.514 7.33e-11 ***
S2WantShout-C1  0.94530    0.21337   4.430 9.41e-06 ***
S2WantShout-C2  2.11747    0.36503   5.801 6.60e-09 ***
S2DoShout-C1    2.12473    0.22734   9.346  < 2e-16 ***
S2DoShout-C2    4.40992    0.41996  10.501  < 2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Log-likelihood: -2475 (df = 23) 
Number of iterations in BFGS optimization: 32 

> plot(pcm)
> 
> ## Get data of situation 1 ('A bus fails to
> ## stop for me') and induce a null category in item 2.
> pcd <- VerbalAggression$resp[, 1:6, drop = FALSE]
> pcd[pcd[, 2] == 1, 2] <- NA
> 
> ## fit pcm to these data, comparing downcoding and keeping strategy
> pcm_va_keep  <- PCModel.fit(pcd, nullcats = "keep")
Warning in PCModel.fit(pcd, nullcats = "keep") :
  There are items with null categories (I2).
> pcm_va_down  <- PCModel.fit(pcd, nullcats = "downcode")
Warning in PCModel.fit(pcd, nullcats = "downcode") :
  There are items with null categories (I2).
> 
> plot(x = coef(pcm_va_keep), y = coef(pcm_va_down),
+      xlab = "Threshold Parameters (Downcoding)",
+      ylab = "Threshold Parameters (Keeping)",
+      main = "Comparison of two null category strategies (I2 with null category)", 
+      pch = rep(as.character(1:6), each = 2)[-3])
> abline(b = 1, a = 0)
> 
> 
> 
> 
> cleanEx()
> nameEx("RSModel.fit")
> ### * RSModel.fit
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: RSModel.fit
> ### Title: Rating Scale Model Fitting Function
> ### Aliases: RSModel.fit print.RSModel summary.RSModel
> ###   print.summary.RSModel coef.RSModel logLik.RSModel vcov.RSModel
> ### Keywords: regression
> 
> ### ** Examples
> 
> 
> ## Verbal aggression data
> data("VerbalAggression", package = "psychotools")
> 
> ## Rating scale model for the other-to-blame situations
> rsm <- RSModel.fit(VerbalAggression$resp[, 1:12])
> summary(rsm)

Rating scale model

Item location and threshold parameters:
            Estimate Std. Error z value Pr(>|z|)    
S1DoCurse    0.08993    0.11766   0.764 0.444669    
S1WantScold  0.42045    0.11812   3.560 0.000371 ***
S1DoScold    0.63786    0.11936   5.344 9.09e-08 ***
S1WantShout  0.91614    0.12201   7.509 5.96e-14 ***
S1DoShout    1.56572    0.13298  11.774  < 2e-16 ***
S2WantCurse -0.21823    0.11886  -1.836 0.066365 .  
S2DoCurse    0.26187    0.11768   2.225 0.026062 *  
S2WantScold  0.35824    0.11790   3.039 0.002377 ** 
S2DoScold    0.98491    0.12284   8.018 1.08e-15 ***
S2WantShout  0.86353    0.12141   7.112 1.14e-12 ***
S2DoShout    2.05975    0.14660  14.050  < 2e-16 ***
C2           0.50240    0.08499   5.911 3.40e-09 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Log-likelihood: -2481 (df = 12) 
Number of iterations in BFGS optimization: 19 

> plot(rsm)
> 
> 
> 
> 
> cleanEx()
> nameEx("RaschModel.fit")
> ### * RaschModel.fit
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: RaschModel.fit
> ### Title: Rasch Model Fitting Function
> ### Aliases: RaschModel.fit print.RaschModel summary.RaschModel
> ###   print.summary.RaschModel coef.RaschModel worth.RaschModel
> ###   logLik.RaschModel vcov.RaschModel
> ### Keywords: regression
> 
> ### ** Examples
> 
> ## Verbal aggression data
> data("VerbalAggression", package = "psychotools")
> 
> ## Rasch model for the other-to-blame situations
> m <- RaschModel.fit(VerbalAggression$resp2[, 1:12])
> summary(m)

Rasch model

Difficulty parameters:
              Estimate Std. Error z value Pr(>|z|)    
S1DoCurse   -1.556e-08  2.042e-01   0.000  1.00000    
S1WantScold  6.857e-01  1.995e-01   3.436  0.00059 ***
S1DoScold    8.727e-01  1.994e-01   4.376 1.21e-05 ***
S1WantShout  1.208e+00  2.003e-01   6.032 1.62e-09 ***
S1DoShout    2.294e+00  2.131e-01  10.766  < 2e-16 ***
S2WantCurse -5.393e-01  2.135e-01  -2.527  0.01152 *  
S2DoCurse    3.614e-01  2.009e-01   1.799  0.07200 .  
S2WantScold  5.345e-01  2.000e-01   2.673  0.00753 ** 
S2DoScold    1.359e+00  2.012e-01   6.755 1.42e-11 ***
S2WantShout  1.283e+00  2.007e-01   6.395 1.61e-10 ***
S2DoShout    3.067e+00  2.343e-01  13.088  < 2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Log-likelihood: -1255 (df = 11) 
Number of iterations in BFGS optimization: 19 

> plot(m)
> 
> 
> 
> cleanEx()
> nameEx("SoundQuality")
> ### * SoundQuality
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: SoundQuality
> ### Title: Quality of Multichannel Reproduced Sound
> ### Aliases: SoundQuality
> ### Keywords: datasets
> 
> ### ** Examples
> 
> data("SoundQuality", package = "psychotools")
> summary(SoundQuality$preference)
                            >   <
Mono        : PhantomMono 515 268
Mono        : Stereo      737  46
PhantomMono : Stereo      698  85
Mono        : WideStereo  689  94
PhantomMono : WideStereo  657 126
Stereo      : WideStereo  315 468
Mono        : Matrix      718  65
PhantomMono : Matrix      684  99
Stereo      : Matrix      392 391
WideStereo  : Matrix      425 358
Mono        : Upmix1      718  65
PhantomMono : Upmix1      679 104
Stereo      : Upmix1      340 443
WideStereo  : Upmix1      389 394
Matrix      : Upmix1      372 411
Mono        : Upmix2      702  81
PhantomMono : Upmix2      641 142
Stereo      : Upmix2      279 504
WideStereo  : Upmix2      347 436
Matrix      : Upmix2      325 458
Upmix1      : Upmix2      351 432
Mono        : Original    722  61
PhantomMono : Original    682 101
Stereo      : Original    384 399
WideStereo  : Original    414 369
Matrix      : Original    402 381
Upmix1      : Original    410 373
Upmix2      : Original    450 333
> ftable(xtabs(~ time + repet + progmat, data = SoundQuality))
             progmat Beethoven Rachmaninov SteelyDan Sting
time   repet                                              
before 1                    39          39        40    39
       2                    39          39        40    39
       3                    39          39        40    39
after  1                    39          39        39    39
       2                    39          39        39    39
       3                     0           0         0     0
> 
> 
> 
> cleanEx()
> nameEx("SourceMonitoring")
> ### * SourceMonitoring
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: SourceMonitoring
> ### Title: Performance in a Source-Monitoring Experiment
> ### Aliases: SourceMonitoring
> ### Keywords: datasets
> 
> ### ** Examples
> 
> data("SourceMonitoring", package = "psychotools")
> xtabs(~ gender + I(age >= 30) + sources, SourceMonitoring)
, , sources = think-say

        I(age >= 30)
gender   FALSE TRUE
  female    16   16
  male      16   16

, , sources = write-say

        I(age >= 30)
gender   FALSE TRUE
  female    16   16
  male      16   16

> 
> 
> 
> cleanEx()
> nameEx("StereotypeThreat")
> ### * StereotypeThreat
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: StereotypeThreat
> ### Title: Stereotype Threat in Dutch Differential Aptitude Test
> ### Aliases: StereotypeThreat
> ### Keywords: datasets
> 
> ### ** Examples
> 
> ## Data: Load and include/order wrt group variable
> data("StereotypeThreat", package = "psychotools")
> StereotypeThreat <- transform(StereotypeThreat, group = interaction(ethnicity, condition))
> StereotypeThreat <- StereotypeThreat[order(StereotypeThreat$group),]
> 
> ## Exploratory analysis (Table 2, p. 703)
> tab2 <- with(StereotypeThreat, rbind(
+    "#"         = tapply(numerical, group, length),
+    "Numerical" = tapply(numerical, group, mean),
+    "         " = tapply(numerical, group, sd),
+    "Abstract " = tapply(abstract,  group, mean),
+    "         " = tapply(abstract,  group, sd),
+    "Verbal   " = tapply(verbal,    group, mean),
+    "         " = tapply(verbal,    group, sd)))
> round(tab2, digits = 2)
          majority.control minority.control majority.threat minority.threat
#                    79.00            65.00           78.00           73.00
Numerical             5.35             4.88            5.49            4.67
                      2.54             2.47            2.31            2.52
Abstract             10.42             6.80            9.24            7.34
                      2.96             3.33            3.34            2.83
Verbal                7.27             5.37            6.65            5.56
                      3.01             2.82            3.47            2.70
> 
> ## Corresponding boxplots
> plot(numerical ~ group, data = StereotypeThreat)
> plot(abstract  ~ group, data = StereotypeThreat)
> plot(verbal    ~ group, data = StereotypeThreat)
> 
> ## MANOVA (p. 703)
> m <- lm(cbind(numerical, abstract, verbal) ~ ethnicity * condition, data = StereotypeThreat)
> anova(m, update(m, . ~ . - ethnicity:condition))
Analysis of Variance Table

Model 1: cbind(numerical, abstract, verbal) ~ ethnicity * condition
Model 2: cbind(numerical, abstract, verbal) ~ ethnicity + condition
  Res.Df Df Gen.var.   Pillai approx F num Df den Df  Pr(>F)  
1    291      7.5292                                          
2    292  1   7.5714 0.026692   2.6419      3    289 0.04961 *
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
> ## corresponding univariate results
> printCoefmat(t(sapply(summary(m),
+   function(x) x$coefficients["ethnicityminority:conditionthreat", ])))
                   Estimate Std. Error t value Pr(>|t|)  
Response numerical -0.33844    0.57424 -0.5894  0.55607  
Response abstract   1.71660    0.72798  2.3580  0.01903 *
Response verbal     0.80439    0.70783  1.1364  0.25672  
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
> 
> ## MGCFA (Table 3, p. 704)
> ## can be replicated using package lavaan
> ## Not run: 
> ##D ## convenience function for multi-group CFA on this data
> ##D mgcfa <- function(model, ...) cfa(model, data = StereotypeThreat,
> ##D   group = "group", likelihood = "wishart", start = "simple", ...)
> ##D 		 
> ##D ## list of all 9 models
> ##D m <- vector("list", length = 9)
> ##D names(m) <- c("m2", "m2a", "m3", "m3a", "m4", "m5", "m5a", "m5b", "m6")
> ##D 
> ##D ## Step 2: Fix loadings across groups
> ##D f <- 'ability =~ abstract + verbal + numerical'
> ##D m$m2 <- mgcfa(f, group.equal = "loadings")
> ##D 
> ##D ## Step 2a: Free numerical loading in group 4 (minority.threat)
> ##D f <- 'ability =~ abstract + verbal + c(l1, l1, l1, l4) * numerical'
> ##D m$m2a <- mgcfa(f, group.equal = "loadings")
> ##D 
> ##D ## Step 3: Fix variances across groups
> ##D m$m3 <- mgcfa(f, group.equal = c("loadings", "residuals"))
> ##D 
> ##D ## Step 3a: Free numerical variance in group 4
> ##D f <- c(f, 'numerical ~~ c(e1, e1, e1, e4) * numerical')
> ##D m$m3a <- mgcfa(f, group.equal = c("loadings", "residuals"))
> ##D 
> ##D ## Step 4: Fix latent variances within conditions
> ##D f <- c(f, 'ability ~~ c(vmaj, vmin, vmaj, vmin) * ability')
> ##D m$m4 <- mgcfa(f, group.equal = c("loadings", "residuals"))
> ##D 
> ##D ## Step 5: Fix certain means, free others
> ##D f <- c(f, 'numerical ~ c(na1, na1, na1, na4) * 1')
> ##D m$m5 <- mgcfa(f, group.equal = c("loadings", "residuals", "intercepts"))
> ##D 
> ##D ## Step 5a: Free ability mean in group majority.control
> ##D f <- c(f, 'abstract ~ c(ar1, ar2, ar2, ar2) * 1')
> ##D m$m5a <- mgcfa(f, group.equal = c("loadings", "residuals", "intercepts"))
> ##D 
> ##D ## Step 5b: Free also ability mean in group minority.control
> ##D f <- c(f[1:4], 'abstract ~ c(ar1, ar2, ar3, ar3) * 1')
> ##D m$m5b <- mgcfa(f, group.equal = c("loadings", "residuals", "intercepts"))
> ##D 
> ##D ## Step 6: Different latent mean structure
> ##D f <- c(f, 'ability ~  c(maj, min1, maj, min2) * 1 + c(NA, 0, NA, 0) * 1')
> ##D m$m6 <- mgcfa(f, group.equal = c("loadings", "residuals", "intercepts"))
> ##D 
> ##D ## Extract measures of fit
> ##D tab <- t(sapply(m, fitMeasures, c("chisq", "df", "pvalue", "rmsea", "cfi")))
> ##D tab <- rbind("1" = c(0, 0, 1, 0, 1), tab)
> ##D tab <- cbind(tab,
> ##D   delta_chisq = c(NA, abs(diff(tab[, "chisq"]))),
> ##D   delta_df = c(NA, diff(tab[, "df"])))
> ##D tab <- cbind(tab, "pvalue2" = pchisq(tab[, "delta_chisq"],
> ##D   abs(tab[, "delta_df"]), lower.tail = FALSE))
> ##D tab <- tab[, c(2, 1, 3, 7, 6, 8, 4, 5)]
> ##D round(tab, digits = 3)
> ## End(Not run)
> 
> 
> 
> cleanEx()
> nameEx("VerbalAggression")
> ### * VerbalAggression
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: VerbalAggression
> ### Title: Situation-Response Questionnaire on Verbal Aggression
> ### Aliases: VerbalAggression
> ### Keywords: datasets
> 
> ### ** Examples
> 
> data("VerbalAggression", package = "psychotools")
> 
> ## Rasch model for the self-to-blame situations
> m <- RaschModel.fit(VerbalAggression$resp2[, 1:12])
> summary(m)

Rasch model

Difficulty parameters:
              Estimate Std. Error z value Pr(>|z|)    
S1DoCurse   -1.556e-08  2.042e-01   0.000  1.00000    
S1WantScold  6.857e-01  1.995e-01   3.436  0.00059 ***
S1DoScold    8.727e-01  1.994e-01   4.376 1.21e-05 ***
S1WantShout  1.208e+00  2.003e-01   6.032 1.62e-09 ***
S1DoShout    2.294e+00  2.131e-01  10.766  < 2e-16 ***
S2WantCurse -5.393e-01  2.135e-01  -2.527  0.01152 *  
S2DoCurse    3.614e-01  2.009e-01   1.799  0.07200 .  
S2WantScold  5.345e-01  2.000e-01   2.673  0.00753 ** 
S2DoScold    1.359e+00  2.012e-01   6.755 1.42e-11 ***
S2WantShout  1.283e+00  2.007e-01   6.395 1.61e-10 ***
S2DoShout    3.067e+00  2.343e-01  13.088  < 2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Log-likelihood: -1255 (df = 11) 
Number of iterations in BFGS optimization: 19 

> plot(m)
> 
> 
> 
> cleanEx()
> nameEx("YouthGratitude")
> ### * YouthGratitude
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: YouthGratitude
> ### Title: Measuring Gratitude in Youth
> ### Aliases: YouthGratitude
> ### Keywords: datasets
> 
> ### ** Examples
> 
> data("YouthGratitude", package = "psychotools")
> summary(YouthGratitude)
       id              age         agegroup       gq6_1           gq6_2      
 Min.   :   1.0   Min.   :10.00   10-11:217   Min.   :1.000   Min.   :1.000  
 1st Qu.: 244.8   1st Qu.:13.00   12-13:194   1st Qu.:6.000   1st Qu.:5.000  
 Median : 498.5   Median :15.00   14   :211   Median :6.000   Median :6.000  
 Mean   : 511.5   Mean   :14.47   15   :249   Mean   :6.111   Mean   :5.856  
 3rd Qu.: 778.2   3rd Qu.:16.00   16   :260   3rd Qu.:7.000   3rd Qu.:7.000  
 Max.   :1098.0   Max.   :19.00   17-19:274   Max.   :7.000   Max.   :7.000  
 NA's   :1                                                                   
     gq6_3          gq6_4           gq6_5           gq6_6           gac_1      
 Min.   :1.00   Min.   :1.000   Min.   :1.000   Min.   :1.000   Min.   :1.000  
 1st Qu.:5.00   1st Qu.:5.000   1st Qu.:5.000   1st Qu.:3.000   1st Qu.:3.000  
 Median :6.00   Median :6.000   Median :6.000   Median :4.000   Median :4.000  
 Mean   :5.72   Mean   :5.551   Mean   :5.918   Mean   :4.453   Mean   :3.817  
 3rd Qu.:7.00   3rd Qu.:6.000   3rd Qu.:7.000   3rd Qu.:6.000   3rd Qu.:5.000  
 Max.   :7.00   Max.   :7.000   Max.   :7.000   Max.   :7.000   Max.   :5.000  
                                                                               
     gac_2           gac_3           losd_1          losd_2     
 Min.   :1.000   Min.   :1.000   Min.   :1.000   Min.   :1.000  
 1st Qu.:3.000   1st Qu.:3.000   1st Qu.:6.000   1st Qu.:4.000  
 Median :4.000   Median :4.000   Median :7.000   Median :6.000  
 Mean   :3.886   Mean   :3.966   Mean   :7.133   Mean   :5.734  
 3rd Qu.:5.000   3rd Qu.:5.000   3rd Qu.:9.000   3rd Qu.:8.000  
 Max.   :5.000   Max.   :5.000   Max.   :9.000   Max.   :9.000  
                                                                
     losd_3          losd_4          losd_5          losd_6     
 Min.   :1.000   Min.   :1.000   Min.   :1.000   Min.   :1.000  
 1st Qu.:3.000   1st Qu.:3.000   1st Qu.:4.000   1st Qu.:4.000  
 Median :5.000   Median :5.000   Median :6.000   Median :5.000  
 Mean   :5.289   Mean   :5.345   Mean   :5.846   Mean   :5.389  
 3rd Qu.:8.000   3rd Qu.:8.000   3rd Qu.:9.000   3rd Qu.:7.000  
 Max.   :9.000   Max.   :9.000   Max.   :9.000   Max.   :9.000  
                                                                
      sa_1            sa_2            sa_3            sa_4      
 Min.   :1.000   Min.   :1.000   Min.   :1.000   Min.   :1.000  
 1st Qu.:3.000   1st Qu.:2.000   1st Qu.:4.000   1st Qu.:5.000  
 Median :5.000   Median :5.000   Median :5.000   Median :6.000  
 Mean   :5.035   Mean   :4.696   Mean   :5.444   Mean   :5.723  
 3rd Qu.:7.000   3rd Qu.:6.000   3rd Qu.:7.000   3rd Qu.:7.607  
 Max.   :9.000   Max.   :9.000   Max.   :9.000   Max.   :9.000  
                                                                
      sa_5            sa_6            ao_1            ao_2      
 Min.   :1.000   Min.   :1.000   Min.   :1.000   Min.   :1.000  
 1st Qu.:6.000   1st Qu.:7.000   1st Qu.:6.000   1st Qu.:6.000  
 Median :7.000   Median :9.000   Median :7.000   Median :7.000  
 Mean   :7.052   Mean   :7.669   Mean   :6.772   Mean   :6.739  
 3rd Qu.:9.000   3rd Qu.:9.000   3rd Qu.:9.000   3rd Qu.:8.000  
 Max.   :9.000   Max.   :9.000   Max.   :9.000   Max.   :9.000  
                                                                
      ao_3            ao_4       
 Min.   :1.000   Min.   : 1.000  
 1st Qu.:5.000   1st Qu.: 6.000  
 Median :7.000   Median : 7.000  
 Mean   :6.404   Mean   : 7.278  
 3rd Qu.:8.000   3rd Qu.: 9.000  
 Max.   :9.000   Max.   :34.203  
                                 
> 
> ## modeling can be carried out using package lavaan
> ## Not run: 
> ##D ## remove cases with 'imputed' values (not in 1, ..., 9)
> ##D yg <- YouthGratitude[apply(YouthGratitude[, 4:28], 1, function(x) all(x ##D 
> ##D 
> ##D ## GQ-6
> ##D gq6_congeneric <- cfa(
> ##D   'f1 =~ gq6_1 + gq6_2 + gq6_3 + gq6_4 + gq6_5',
> ##D   data = yg, group = "agegroup", meanstructure = TRUE)
> ##D gq6_tauequivalent <- cfa(
> ##D   'f1 =~ gq6_1 + gq6_2 + gq6_3 + gq6_4 + gq6_5',
> ##D   data = yg, group = "agegroup", meanstructure = TRUE,
> ##D   group.equal = "loadings")
> ##D gq6_parallel <- cfa(
> ##D   'f1 =~ gq6_1 + gq6_2 + gq6_3 + gq6_4 + gq6_5',
> ##D   data = yg, group = "agegroup", meanstructure = TRUE,
> ##D   group.equal = c("loadings", "residuals", "lv.variances"))
> ##D anova(gq6_congeneric, gq6_tauequivalent, gq6_parallel)
> ##D t(sapply(
> ##D   list(gq6_congeneric, gq6_tauequivalent, gq6_parallel),
> ##D   function(m) fitMeasures(m)[c("chisq", "df", "cfi", "srmr")]
> ##D ))
> ##D 
> ##D ## GAC
> ##D gac_congeneric <- cfa(
> ##D   'f1 =~ gac_1 + gac_2 + gac_3',
> ##D   data = yg, group = "agegroup", meanstructure = TRUE)
> ##D gac_tauequivalent <- cfa(
> ##D   'f1 =~ gac_1 + gac_2 + gac_3',
> ##D   data = yg, group = "agegroup", meanstructure = TRUE,
> ##D   group.equal = "loadings")
> ##D gac_parallel <- cfa(
> ##D   'f1 =~ gac_1 + gac_2 + gac_3',
> ##D   data = yg, group = "agegroup", meanstructure = TRUE,
> ##D   group.equal = c("loadings", "residuals", "lv.variances"))
> ##D anova(gac_congeneric, gac_tauequivalent, gac_parallel)
> ##D t(sapply(
> ##D   list(gac_congeneric, gac_tauequivalent, gac_parallel),
> ##D   function(m) fitMeasures(m)[c("chisq", "df", "cfi", "srmr")]
> ##D ))
> ##D 
> ##D ## GRAT
> ##D grat_congeneric <- cfa(
> ##D   'f1 =~ losd_2 + losd_3 + losd_4 + losd_5 + losd_6
> ##D    f2 =~ sa_1 + sa_2 + sa_3 + sa_4 + sa_5 + sa_6
> ##D    f3 =~ ao_1 + ao_2 + ao_3 + ao_4',
> ##D   data = yg, group = "agegroup", meanstructure = TRUE)
> ##D grat_tauequivalent <- cfa(
> ##D   'f1 =~ losd_2 + losd_3 + losd_4 + losd_5 + losd_6
> ##D    f2 =~ sa_1 + sa_2 + sa_3 + sa_4 + sa_5 + sa_6
> ##D    f3 =~ ao_1 + ao_2 + ao_3 + ao_4',
> ##D   data = yg, group = "agegroup", meanstructure = TRUE,
> ##D   group.equal = "loadings")
> ##D grat_parallel <- cfa(
> ##D   'f1 =~ losd_2 + losd_3 + losd_4 + losd_5 + losd_6
> ##D    f2 =~ sa_1 + sa_2 + sa_3 + sa_4 + sa_5 + sa_6
> ##D    f3 =~ ao_1 + ao_2 + ao_3 + ao_4',
> ##D   data = yg, group = "agegroup", meanstructure = TRUE,
> ##D   group.equal = c("loadings", "residuals", "lv.variances"))
> ##D anova(grat_congeneric, grat_tauequivalent, grat_parallel)
> ##D t(sapply(
> ##D   list(grat_congeneric, grat_tauequivalent, grat_parallel),
> ##D   function(m) fitMeasures(m)[c("chisq", "df", "cfi", "srmr")]
> ##D ))
> ## End(Not run)
> 
> 
> 
> cleanEx()
> nameEx("btReg.fit")
> ### * btReg.fit
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: btReg.fit
> ### Title: Bradley-Terry Model Fitting Function
> ### Aliases: btReg.fit print.btReg summary.btReg print.summary.btReg
> ###   coef.btReg worth.btReg deviance.btReg logLik.btReg vcov.btReg
> ### Keywords: regression
> 
> ### ** Examples
> 
> ## data
> data("GermanParties2009", package = "psychotools")
> 
> ## Bradley-Terry model
> bt <- btReg.fit(GermanParties2009$preference)
> summary(bt)

Bradley-Terry regression model

Parameters:
        Estimate Std. Error z value Pr(>|z|)    
none    -0.37556    0.08902  -4.219 2.45e-05 ***
Linke   -0.61607    0.09102  -6.768 1.30e-11 ***
Gruene   1.18576    0.09507  12.473  < 2e-16 ***
SPD      0.81310    0.09067   8.967  < 2e-16 ***
CDU/CSU  0.17562    0.08750   2.007   0.0447 *  
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Log-likelihood: -1717 (df = 5) 

> plot(bt)
> 
> 
> 
> cleanEx()
> nameEx("covariates")
> ### * covariates
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: covariates
> ### Title: Extract/Set Covariates
> ### Aliases: covariates covariates<-
> ### Keywords: classes
> 
> ### ** Examples
> 
> ## method for "paircomp" data
> pc <- paircomp(rbind(
+   c(1,  1,  1), # a > b, a > c, b > c
+   c(1,  1, -1), # a > b, a > c, b < c
+   c(1, -1, -1), # a > b, a < c, b < c
+   c(1,  1,  1)))
> covariates(pc)
NULL
> covariates(pc) <- data.frame(foo = factor(c(1, 2, 2), labels = c("foo", "bar")))
> covariates(pc)
  foo
a foo
b bar
c bar
> 
> 
> 
> cleanEx()
> nameEx("elementary_symmetric_functions")
> ### * elementary_symmetric_functions
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: elementary_symmetric_functions
> ### Title: Calculation of the Elementary Symmetric Functions and Their
> ###   Derivatives
> ### Aliases: elementary_symmetric_functions
> ### Keywords: misc
> 
> ### ** Examples
> 
> 
>  ## calculate zero and first order elementary symmetric functions
>  ## for 10 polytomous items with three categories each.
>  pi <- split(rnorm(20), rep(1:10, each = 2))
>  x <- elementary_symmetric_functions(pi)
> 
>  ## use difference algorithm instead and compare results
>  y <- elementary_symmetric_functions(pi, diff = TRUE)
>  all.equal(x, y)
[1] TRUE
> 
> 
> 
> cleanEx()
> nameEx("labels")
> ### * labels
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: labels<-
> ### Title: Set Labels
> ### Aliases: labels<-
> ### Keywords: classes
> 
> ### ** Examples
> 
> ## method for "paircomp" data
> pc <- paircomp(rbind(
+   c(1,  1,  1), # a > b, a > c, b > c
+   c(1,  1, -1), # a > b, a > c, b < c
+   c(1, -1, -1), # a > b, a < c, b < c
+   c(1,  1,  1)))
> labels(pc)
[1] "a" "b" "c"
> labels(pc) <- c("ah", "be", "ce")
> pc
[1] {ah > be, ah > ce, be > ce} {ah > be, ah > ce, be < ce}
[3] {ah > be, ah < ce, be < ce} {ah > be, ah > ce, be > ce}
> 
> 
> 
> cleanEx()
> nameEx("mscale")
> ### * mscale
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: mscale
> ### Title: Extract/Replace Measurement Scale
> ### Aliases: mscale mscale<-
> ### Keywords: classes
> 
> ### ** Examples
> 
> ## methods for "paircomp" data
> pc <- paircomp(rbind(
+   c(2,  1,  0),
+   c(1,  1, -1),
+   c(1, -2, -1),
+   c(0,  0,  0)))
> pc
[1] {a >> b, a > c, b = c} {a > b, a > c, b < c}  {a > b, a << c, b < c}
[4] {a = b, a = c, b = c} 
> 
> ## extract
> mscale(pc)
[1] -2 -1  0  1  2
> 
> ## replace (collapse to >/=/< scale)
> mscale(pc) <- sign(mscale(pc))
> pc
[1] {a > b, a > c, b = c} {a > b, a > c, b < c} {a > b, a < c, b < c}
[4] {a = b, a = c, b = c}
> 
> 
> 
> 
> cleanEx()
> nameEx("paircomp")
> ### * paircomp
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: paircomp
> ### Title: Data Structure for Paired Comparisons
> ### Aliases: paircomp length.paircomp c.paircomp [.paircomp rep.paircomp
> ###   xtfrm.paircomp as.character.paircomp as.data.frame.paircomp
> ###   as.double.paircomp as.integer.paircomp as.matrix.paircomp
> ###   covariates.paircomp covariates<-.paircomp labels.paircomp
> ###   labels<-.paircomp names.paircomp names<-.paircomp mscale.paircomp
> ###   mscale<-.paircomp str.paircomp summary.paircomp is.na.paircomp
> ### Keywords: classes
> 
> ### ** Examples
> 
> ## a simple paired comparison
> pc <- paircomp(rbind(
+   c(1,  1,  1), # a > b, a > c, b > c
+   c(1,  1, -1), # a > b, a > c, b < c
+   c(1, -1, -1), # a > b, a < c, b < c
+   c(1,  1,  1)))
> 
> ## basic methods
> pc
[1] {a > b, a > c, b > c} {a > b, a > c, b < c} {a > b, a < c, b < c}
[4] {a > b, a > c, b > c}
> str(pc)
 Paired comparisons from 4 subjects for 3 objects: a, b, c.
> summary(pc)
      > <
a : b 4 0
a : c 3 1
b : c 2 2
> pc[2:3]
[1] {a > b, a > c, b < c} {a > b, a < c, b < c}
> c(pc[2], pc[c(1, 4)])
[1] {a > b, a > c, b < c} {a > b, a > c, b > c} {a > b, a > c, b > c}
> 
> ## methods to extract/set attributes
> labels(pc)
[1] "a" "b" "c"
> labels(pc) <- c("ah", "be", "ce")
> pc
[1] {ah > be, ah > ce, be > ce} {ah > be, ah > ce, be < ce}
[3] {ah > be, ah < ce, be < ce} {ah > be, ah > ce, be > ce}
> mscale(pc)
[1] -1  1
> covariates(pc)
NULL
> covariates(pc) <- data.frame(foo = factor(c(1, 2, 2), labels = c("foo", "bar")))
> covariates(pc)
   foo
ah foo
be bar
ce bar
> names(pc)
NULL
> names(pc) <- LETTERS[1:4]
> pc
                          A                           B 
{ah > be, ah > ce, be > ce} {ah > be, ah > ce, be < ce} 
                          C                           D 
{ah > be, ah < ce, be < ce} {ah > be, ah > ce, be > ce} 
> 
> ## reorder() and subset() both select a subset of
> ## objects and/or reorders the objects
> reorder(pc, c("ce", "ah"))
        A         B         C         D 
{ce < ah} {ce < ah} {ce > ah} {ce < ah} 
> 
> 
> ## include paircomp object in a data.frame
> ## (i.e., with subject covariates)
> dat <- data.frame(
+   x = rnorm(4),
+   y = factor(c(1, 2, 1, 1), labels = c("hansi", "beppi")))
> dat$pc <- pc
> dat
           x     y                          pc
1 -0.6264538 hansi {ah > be, ah > ce, be > ce}
2  0.1836433 beppi {ah > be, ah > ce, be < ce}
3 -0.8356286 hansi {ah > be, ah < ce, be < ce}
4  1.5952808 hansi {ah > be, ah > ce, be > ce}
> 
> 
> ## formatting with long(er) labels and extended scale
> pc2 <- paircomp(rbind(
+   c(4,  1,  0),
+   c(1,  2, -1),
+   c(1, -2, -1),
+   c(0,  0,  -3)),
+   labels = c("Nordrhein-Westfalen", "Schleswig-Holstein", "Baden-Wuerttemberg"))
> ## default: abbreviate
> print(pc2)
[1] {Nr-W 4> Sc-H, Nr-W > Bd-W, Sc-H = Bd-W}
[2] {Nr-W > Sc-H, Nr-W 2> Bd-W, Sc-H < Bd-W}
[3] {Nr-W > Sc-H, Nr-W 2< Bd-W, Sc-H < Bd-W}
[4] {Nr-W = Sc-H, Nr-W = Bd-W, Sc-H 3< Bd-W}
> print(pc2, abbreviate = FALSE)
[1] {Nordrhein-Westfalen 4> Schleswig-Holstein, Nordrhein-Westfalen > Bad...}
[2] {Nordrhein-Westfalen > Schleswig-Holstein, Nordrhein-Westfalen 2> Bad...}
[3] {Nordrhein-Westfalen > Schleswig-Holstein, Nordrhein-Westfalen 2< Bad...}
[4] {Nordrhein-Westfalen = Schleswig-Holstein, Nordrhein-Westfalen = Bade...}
> print(pc2, abbreviate = FALSE, width = FALSE)
[1] {Nordrhein-Westfalen 4> Schleswig-Holstein, Nordrhein-Westfalen > Baden-Wuerttemberg, Schleswig-Holstein = Baden-Wuerttemberg}
[2] {Nordrhein-Westfalen > Schleswig-Holstein, Nordrhein-Westfalen 2> Baden-Wuerttemberg, Schleswig-Holstein < Baden-Wuerttemberg}
[3] {Nordrhein-Westfalen > Schleswig-Holstein, Nordrhein-Westfalen 2< Baden-Wuerttemberg, Schleswig-Holstein < Baden-Wuerttemberg}
[4] {Nordrhein-Westfalen = Schleswig-Holstein, Nordrhein-Westfalen = Baden-Wuerttemberg, Schleswig-Holstein 3< Baden-Wuerttemberg}
> 
> 
> ## paired comparisons with object covariates
> pc3 <- paircomp(rbind(
+   c(2,  1,  0),
+   c(1,  1, -1),
+   c(1, -2, -1),
+   c(0,  0,  0)),
+   labels = c("New York", "Rio", "Tokyo"),
+   covariates = data.frame(hemisphere = factor(c(1, 2, 1), labels = c("North", "South"))))
> covariates(pc3)
         hemisphere
New York      North
Rio           South
Tokyo         North
> 
> 
> 
> cleanEx()
> nameEx("plot.PCModel")
> ### * plot.PCModel
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: plot.PCModel
> ### Title: Visualizing Partial Credit Models
> ### Aliases: plot.PCModel
> ### Keywords: hplot
> 
> ### ** Examples
> 
> 
> ## Verbal aggression data
> data("VerbalAggression", package = "psychotools")
> 
> ## Partial credit model for the first other-to-blame
> ## situation: 'A bus fails to stop for me'
> pcm <- PCModel.fit(VerbalAggression$resp[, 1:6])
> 
> ## Effect plot with modus as cutpoint and custom labels.
> lab <- paste(rep(c("Curse", "Scold", "Shout"), each = 2),
+              rep(c("Want", "Do"), 3 ), sep = "-")
> plot(pcm, names = lab)
> 
> ## Compare the cutpoints (with ylim specified manually)
> ylim <- c(-2, 2)
> layout(matrix(1:3, ncol = 1))
> plot(pcm, type = "mode", main = "Modus as Cutpoint", ylim = ylim) 
> plot(pcm, type = "median", main = "Median as Cutpoint", ylim = ylim)
> plot(pcm, type = "mean", main = "Mean as Cutpoint", ylim = ylim)
> 
> ## Partial credit model for full VerbalAggression data set
> pcm_va <- PCModel.fit(VerbalAggression$resp)
> plot(pcm_va)
> 
> 
> 
> 
> cleanEx()
> nameEx("plot.RSModel")
> ### * plot.RSModel
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: plot.RSModel
> ### Title: Visualizing Rating Scale Models
> ### Aliases: plot.RSModel
> ### Keywords: hplot
> 
> ### ** Examples
> 
> 
> ## Verbal aggression data
> data("VerbalAggression", package = "psychotools")
> 
> ## Rating scale model for the first other-to-blame
> ## situation: 'A bus fails to stop for me'
> rsm <- RSModel.fit(VerbalAggression$resp[, 1:6])
> 
> ## Basic plot with parameter patterns and custom labels.
> lab <- c(paste(rep(c("Curse", "Scold", "Shout"), each = 2),
+              rep(c("Want", "Do"), 3 ), sep = "-"), "Tau 1", "Tau 2")
> plot(rsm, names = lab)
> 
> ## Basic plot again, but omitting reference and connection lines
> plot(rsm, refline = FALSE, lty = c(0, 0))
> 
> ## Effects plot, similar to effect plots for PCModel's, with
> ## 'modus' as cutpoint via additional argument 'type'.
> plot(rsm, pattern = FALSE, type = "mode")
> 
> 
> 
> 
> cleanEx()
> nameEx("plot.btReg")
> ### * plot.btReg
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: plot.btReg
> ### Title: Visualizing Bradley-Terry Models
> ### Aliases: plot.btReg
> ### Keywords: hplot
> 
> ### ** Examples
> 
> ## data
> data("GermanParties2009", package = "psychotools")
> 
> ## Bradley-Terry model
> bt <- btReg.fit(GermanParties2009$preference)
> plot(bt)
> plot(bt, worth = FALSE)
> plot(bt, index = FALSE)
> 
> 
> 
> cleanEx()
> nameEx("plot.paircomp")
> ### * plot.paircomp
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: plot.paircomp
> ### Title: Plotting Paired Comparison Data
> ### Aliases: plot.paircomp
> ### Keywords: classes
> 
> ### ** Examples
> 
> data("GermanParties2009", package = "psychotools")
> par(mar = c(5, 6, 3, 6))
> plot(GermanParties2009$preference, abbreviate = FALSE)
> 
> 
> 
> graphics::par(get("par.postscript", pos = 'CheckExEnv'))
> cleanEx()
> nameEx("print.paircomp")
> ### * print.paircomp
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: print.paircomp
> ### Title: Formatting Paired Comparison Data
> ### Aliases: print.paircomp format.paircomp
> ### Keywords: classes
> 
> ### ** Examples
> 
> pc2 <- paircomp(rbind(
+   c(4,  1,  0),
+   c(1,  2, -1),
+   c(1, -2, -1),
+   c(0,  0,  -3)),
+   labels = c("New York", "Rio", "Tokyo"))
> 
> print(pc2)
[1] {NwYr 4> Rio, NwYr > Toky, Rio = Toky}
[2] {NwYr > Rio, NwYr 2> Toky, Rio < Toky}
[3] {NwYr > Rio, NwYr 2< Toky, Rio < Toky}
[4] {NwYr = Rio, NwYr = Toky, Rio 3< Toky}
> print(pc2, abbreviate = FALSE)
[1] {New York 4> Rio, New York > Tokyo, Rio = Tokyo}
[2] {New York > Rio, New York 2> Tokyo, Rio < Tokyo}
[3] {New York > Rio, New York 2< Tokyo, Rio < Tokyo}
[4] {New York = Rio, New York = Tokyo, Rio 3< Tokyo}
> print(pc2, abbreviate = FALSE, width = 10)
[1] {New Y...} {New Y...} {New Y...} {New Y...}
> 
> 
> 
> cleanEx()
> nameEx("subset.paircomp")
> ### * subset.paircomp
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: subset.paircomp
> ### Title: Subsetting/Reordering Paired Comparison Data
> ### Aliases: subset.paircomp reorder.paircomp
> ### Keywords: classes
> 
> ### ** Examples
> 
> pc <- paircomp(rbind(
+   c(1,  1,  1), # a > b, a > c, b > c
+   c(1,  1, -1), # a > b, a > c, b < c
+   c(1, -1, -1), # a > b, a < c, b < c
+   c(1,  1,  1)))
> reorder(pc, c("c", "a"))
[1] {c < a} {c < a} {c > a} {c < a}
> 
> 
> 
> cleanEx()
> nameEx("worth")
> ### * worth
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: worth
> ### Title: Extract Worth Parameters
> ### Aliases: worth
> ### Keywords: classes
> 
> ### ** Examples
> 
> ## data
> data("GermanParties2009", package = "psychotools")
> 
> ## Bradley-Terry model
> bt <- btReg.fit(GermanParties2009$preference)
> 
> ## worth parameters
> worth(bt)
      none      Linke     Gruene        SPD    CDU/CSU        FDP 
0.07677476 0.06036248 0.36583889 0.25202703 0.13322747 0.11176938 
> 
> 
> 
> ### * <FOOTER>
> ###
> options(digits = 7L)
> base::cat("Time elapsed: ", proc.time() - base::get("ptime", pos = 'CheckExEnv'),"\n")
Time elapsed:  3.223 0.027 3.259 0 0 
> grDevices::dev.off()
null device 
          1 
> ###
> ### Local variables: ***
> ### mode: outline-minor ***
> ### outline-regexp: "\\(> \\)?### [*]+" ***
> ### End: ***
> quit('no')
